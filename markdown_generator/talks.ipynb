{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Talks markdown generator for academicpages\n",
    "\n",
    "Takes a TSV of talks with metadata and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). The core python code is also in `talks.py`. Run either from the `markdown_generator` folder after replacing `talks.tsv` with one containing your data.\n",
    "\n",
    "TODO: Make this work with BibTex and other databases, rather than Stuart's non-standard TSV format and citation style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "\n",
    "The TSV needs to have the following columns: title, type, url_slug, venue, date, location, talk_url, description, with a header at the top. Many of these fields can be blank, but the columns must be in the TSV.\n",
    "\n",
    "- Fields that cannot be blank: `title`, `url_slug`, `date`. All else can be blank. `type` defaults to \"Talk\" \n",
    "- `date` must be formatted as YYYY-MM-DD.\n",
    "- `url_slug` will be the descriptive part of the .md file and the permalink URL for the page about the paper. \n",
    "    - The .md file will be `YYYY-MM-DD-[url_slug].md` and the permalink will be `https://[yourdomain]/talks/YYYY-MM-DD-[url_slug]`\n",
    "    - The combination of `url_slug` and `date` must be unique, as it will be the basis for your filenames\n",
    "\n",
    "This is how the raw file looks (it doesn't look pretty, use a spreadsheet or other program to edit and create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\ttype\turl_slug\tvenue\tdate\tlocation\ttalk_url\tdescription\n",
      "Enhance Investigation Resolution: Integrating Machine Learning and Core Scanning Techniques\tTalk\ttalk-8\tKochi Core Center\t2025-08-22\tKochi, Japan\n",
      "Translating XRF into Various Measurements with an Inclusive Self-Supervised Model\tTalk\ttalk-7\tNational Institute of Polar Research\t2025-02-20\tTokyo, Japan\n",
      "Machine learning and XRF core scanning: breaking barriers between projects\tTalk\ttalk-6\tRoyal Netherlands Institute for Sea Research (NIOZ)\t2024-10-08\tTexel, Netherlands\n",
      "Pretraining Foundation Models: Unleashing the Power of Forgotten Spectra for Various Geological Applications\tTalk\ttalk-5\tUniversity of Bremen, Institute of Geography\t2024-04-10\tBremen, Germany\n",
      "Scale up geological research capacity: Machine learning and sediment core scanning techniques\tTalk\ttalk-4\tKochi Core Center\t2023-08-28\tKochi, Japan\n",
      "Applying a Machine Learning Approach to Sediment-Facies Classification of Coastal Sediments from Northern Germany\tConference Talk\ttalk-3\tAmerican Geophysical Union Fall Meeting\t2021-12-14\tNew Orleans, USA  \n",
      "Artificial intelligence for facies classification based on high-resolution data from sediments of the Wadden Sea, Germany\tConference Talk\ttalk-2\tJapan Geoscience Union Meeting\t2021-06-03\tChiba, Japan\n",
      "From wiggles to statistics - a few thoughts and tricks when encountering high-resolution XRF-core scanning data of long sedimentary record\tTalk\ttalk-1\tUniversity of Innsbruck, Institute of Geology\t2019-07-20\tInnsbruck, Austria"
     ]
    }
   ],
   "source": [
    "!cat talks.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TSV\n",
    "\n",
    "Pandas makes this easy with the read_csv function. We are using a TSV, so we specify the separator as a tab, or `\\t`.\n",
    "\n",
    "I found it important to put this data in a tab-separated values format, because there are a lot of commas in this kind of data and comma-separated values can get messed up. However, you can modify the import statement, as pandas also has read_excel(), read_json(), and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>url_slug</th>\n",
       "      <th>venue</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>talk_url</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enhance Investigation Resolution: Integrating ...</td>\n",
       "      <td>Talk</td>\n",
       "      <td>talk-8</td>\n",
       "      <td>Kochi Core Center</td>\n",
       "      <td>2025-08-22</td>\n",
       "      <td>Kochi, Japan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Translating XRF into Various Measurements with...</td>\n",
       "      <td>Talk</td>\n",
       "      <td>talk-7</td>\n",
       "      <td>National Institute of Polar Research</td>\n",
       "      <td>2025-02-20</td>\n",
       "      <td>Tokyo, Japan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine learning and XRF core scanning: breaki...</td>\n",
       "      <td>Talk</td>\n",
       "      <td>talk-6</td>\n",
       "      <td>Royal Netherlands Institute for Sea Research (...</td>\n",
       "      <td>2024-10-08</td>\n",
       "      <td>Texel, Netherlands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pretraining Foundation Models: Unleashing the ...</td>\n",
       "      <td>Talk</td>\n",
       "      <td>talk-5</td>\n",
       "      <td>University of Bremen, Institute of Geography</td>\n",
       "      <td>2024-04-10</td>\n",
       "      <td>Bremen, Germany</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scale up geological research capacity: Machine...</td>\n",
       "      <td>Talk</td>\n",
       "      <td>talk-4</td>\n",
       "      <td>Kochi Core Center</td>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>Kochi, Japan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Applying a Machine Learning Approach to Sedime...</td>\n",
       "      <td>Conference Talk</td>\n",
       "      <td>talk-3</td>\n",
       "      <td>American Geophysical Union Fall Meeting</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>New Orleans, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Artificial intelligence for facies classificat...</td>\n",
       "      <td>Conference Talk</td>\n",
       "      <td>talk-2</td>\n",
       "      <td>Japan Geoscience Union Meeting</td>\n",
       "      <td>2021-06-03</td>\n",
       "      <td>Chiba, Japan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>From wiggles to statistics - a few thoughts an...</td>\n",
       "      <td>Talk</td>\n",
       "      <td>talk-1</td>\n",
       "      <td>University of Innsbruck, Institute of Geology</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>Innsbruck, Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title             type  \\\n",
       "0  Enhance Investigation Resolution: Integrating ...             Talk   \n",
       "1  Translating XRF into Various Measurements with...             Talk   \n",
       "2  Machine learning and XRF core scanning: breaki...             Talk   \n",
       "3  Pretraining Foundation Models: Unleashing the ...             Talk   \n",
       "4  Scale up geological research capacity: Machine...             Talk   \n",
       "5  Applying a Machine Learning Approach to Sedime...  Conference Talk   \n",
       "6  Artificial intelligence for facies classificat...  Conference Talk   \n",
       "7  From wiggles to statistics - a few thoughts an...             Talk   \n",
       "\n",
       "  url_slug                                              venue        date  \\\n",
       "0   talk-8                                  Kochi Core Center  2025-08-22   \n",
       "1   talk-7               National Institute of Polar Research  2025-02-20   \n",
       "2   talk-6  Royal Netherlands Institute for Sea Research (...  2024-10-08   \n",
       "3   talk-5       University of Bremen, Institute of Geography  2024-04-10   \n",
       "4   talk-4                                  Kochi Core Center  2023-08-28   \n",
       "5   talk-3            American Geophysical Union Fall Meeting  2021-12-14   \n",
       "6   talk-2                     Japan Geoscience Union Meeting  2021-06-03   \n",
       "7   talk-1      University of Innsbruck, Institute of Geology  2019-07-20   \n",
       "\n",
       "             location  talk_url  description  \n",
       "0        Kochi, Japan       NaN          NaN  \n",
       "1        Tokyo, Japan       NaN          NaN  \n",
       "2  Texel, Netherlands       NaN          NaN  \n",
       "3     Bremen, Germany       NaN          NaN  \n",
       "4        Kochi, Japan       NaN          NaN  \n",
       "5  New Orleans, USA         NaN          NaN  \n",
       "6        Chiba, Japan       NaN          NaN  \n",
       "7  Innsbruck, Austria       NaN          NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talks = pd.read_csv(\"talks.tsv\", sep=\"\\t\", header=0)\n",
    "talks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escape special characters\n",
    "\n",
    "YAML is very picky about how it takes a valid string, so we are replacing single and double quotes (and ampersands) with their HTML encoded equivilents. This makes them look not so readable in raw format, but they are parsed and rendered nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    if type(text) is str:\n",
    "        return \"\".join(html_escape_table.get(c,c) for c in text)\n",
    "    else:\n",
    "        return \"False\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the markdown files\n",
    "\n",
    "This is where the heavy lifting is done. This loops through all the rows in the TSV dataframe, then starts to concatentate a big string (```md```) that contains the markdown for each type. It does the YAML metadata first, then does the description for the individual page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loc_dict = {}\n",
    "\n",
    "for row, item in talks.iterrows():\n",
    "    \n",
    "    md_filename = str(item.date) + \"-\" + item.url_slug + \".md\"\n",
    "    html_filename = str(item.date) + \"-\" + item.url_slug \n",
    "    year = item.date[:4]\n",
    "    \n",
    "    md = \"---\\ntitle: \\\"\"   + item.title + '\"\\n'\n",
    "    md += \"collection: talks\" + \"\\n\"\n",
    "    \n",
    "    if len(str(item.type)) > 3:\n",
    "        md += 'type: \"' + item.type + '\"\\n'\n",
    "    else:\n",
    "        md += 'type: \"Talk\"\\n'\n",
    "    \n",
    "    md += \"permalink: /talks/\" + html_filename + \"\\n\"\n",
    "    \n",
    "    if len(str(item.venue)) > 3:\n",
    "        md += 'venue: \"' + item.venue + '\"\\n'\n",
    "        \n",
    "    if len(str(item.location)) > 3:\n",
    "        md += \"date: \" + str(item.date) + \"\\n\"\n",
    "    \n",
    "    if len(str(item.location)) > 3:\n",
    "        md += 'location: \"' + str(item.location) + '\"\\n'\n",
    "           \n",
    "    md += \"---\\n\"\n",
    "    \n",
    "    \n",
    "    if len(str(item.talk_url)) > 3:\n",
    "        md += \"\\n[More information here](\" + item.talk_url + \")\\n\" \n",
    "        \n",
    "    \n",
    "    if len(str(item.description)) > 3:\n",
    "        md += \"\\n\" + html_escape(item.description) + \"\\n\"\n",
    "        \n",
    "        \n",
    "    md_filename = os.path.basename(md_filename)\n",
    "    #print(md)\n",
    "    \n",
    "    with open(\"../_talks/\" + md_filename, 'w') as f:\n",
    "        f.write(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files are in the talks directory, one directory below where we're working from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-20-talk-1.md  2023-08-28-talk-4.md  2025-02-20-talk-7.md  talkmap.ipynb\n",
      "2021-06-03-talk-2.md  2024-04-10-talk-5.md  2025-08-22-talk-7.md  talkmap.py\n",
      "2021-12-14-talk-3.md  2024-10-08-talk-6.md  2025-08-22-talk-8.md\n"
     ]
    }
   ],
   "source": [
    "!ls ../_talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: ../_talks/2013-03-01-tutorial-1.md: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cat ../_talks/2013-03-01-tutorial-1.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
